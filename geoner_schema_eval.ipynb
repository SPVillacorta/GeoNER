{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP/eA/HM6rFJ4teXLDgDvQH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SPVillacorta/GeoNER-SchemaEval/blob/main/geoner_schema_eval.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluating the Performance of a Trained NER Model using a Confusion Matrix\n",
        "\n",
        "This notebook demonstrates how to evaluate the performance of a pre-trained Named Entity Recognition (NER) model using a confusion matrix and classification report. It specifically uses the Flair NLP framework and `scikit-learn` for evaluation.\n",
        "\n",
        "**Important Note:**\n",
        "For demonstration and reproducibility, this notebook expects the following files to be accessible within a cloned repository structure (or downloaded/provided):\n",
        "* A pre-trained model: `./ozrock/model/best-model.pt`\n",
        "* Example PDF documents: `./ozrock/IRpdfs/`\n",
        "* Annotated dataset: `./ozrock/annotated-ozrock.csv`"
      ],
      "metadata": {
        "id": "1BZdDbdzxl6N"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBIxqRZ35ED8"
      },
      "outputs": [],
      "source": [
        "## 0. Setup and Dependencies\n",
        "\n",
        "First, we need to install the required libraries and download necessary NLTK data.\n",
        "\n",
        "```python\n",
        "# Install required libraries\n",
        "!pip install flair pdfplumber pdfminer scikit-learn pandas seaborn matplotlib numpy\n",
        "\n",
        "# Import necessary modules\n",
        "import glob\n",
        "import nltk\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pdfplumber\n",
        "import pdfminer\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import flair\n",
        "from flair.data import Corpus, Sentence\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import FlairEmbeddings, StackedEmbeddings\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n",
        "from pdfminer.pdfdocument import PDFNoValidXRef\n",
        "from pdfminer.psparser import PSEOF\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from typing import List\n",
        "\n",
        "# Download NLTK data\n",
        "nltk.download(\"punkt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Prepare Your Environment and Data (Google Colab Specific)\n",
        "When running this notebook on Google Colab, you need to clone the GitHub repository to access the model, example PDFs, and annotated data."
      ],
      "metadata": {
        "id": "IxMQ5eLXxr_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone the GitHub repository\n",
        "# Replace 'SPVillacorta/GeoNER-SchemaEval' with your actual GitHub username and repository name if different\n",
        "!git clone [https://github.com/SPVillacorta/GeoNER-SchemaEval.git](https://github.com/SPVillacorta/GeoNER-SchemaEval.git)\n",
        "\n",
        "# Change the current working directory to the cloned repository's root.\n",
        "# This ensures all relative paths (e.g., './ozrock/...') work correctly.\n",
        "import os\n",
        "os.chdir(\"GeoNER-SchemaEval\") # Make sure this matches your repository's folder name\n",
        "print(f\"Current working directory set to: {os.getcwd()}\")\n",
        "!ls -F # Verify the contents of the current directory; you should see 'ozrock/'"
      ],
      "metadata": {
        "id": "LSduSYt9xnTL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. PDF to Sentences Conversion\n",
        "This function extracts text from PDF files within a specified directory and tokenizes it into sentences."
      ],
      "metadata": {
        "id": "qQUe217zyiH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pdf_to_sentences(pdf_dir: str):\n",
        "    pdf_paths = glob.glob(os.path.join(pdf_dir, \"*.pdf\"))\n",
        "    all_sentences = []\n",
        "    for pdf_path in pdf_paths:\n",
        "        try:\n",
        "            with pdfplumber.open(pdf_path) as pdf:\n",
        "                text = \"\\n\".join([page.extract_text() for page in pdf.pages])\n",
        "                sentences = nltk.sent_tokenize(text)\n",
        "                all_sentences.extend(sentences)\n",
        "        except (pdfminer.pdfdocument.PDFNoValidXRef, pdfminer.psparser.PSEOF) as e:\n",
        "            print(f\"Warning: Skipping file {pdf_path} due to an error. {e}\")\n",
        "    return all_sentences"
      ],
      "metadata": {
        "id": "m0GwNiWcyYdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Load the Pre-trained Model\n",
        "Load the pre-trained Flair SequenceTagger model from the specified path.\n",
        "Due to the model's size, it cannot be hosted directly on GitHub. It will be downloaded from an external service."
      ],
      "metadata": {
        "id": "JBiXwClsyuIP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# *** IMPORTANT: Replace 'YOUR_GOOGLE_DRIVE_FILE_ID_HERE' with your actual Google Drive file ID ***\n",
        "# To get the ID:\n",
        "# 1. Upload 'best-model.pt' to your Google Drive.\n",
        "# 2. Right-click the file and select \"Share\" -> \"Share\".\n",
        "# 3. Change access to \"Anyone with the link\".\n",
        "# 4. Copy the link. The ID is the part between /d/ and /view.\n",
        "#    Example: [https://drive.google.com/file/d/THIS_IS_THE_ID/view?usp=sharing](https://drive.google.com/file/d/THIS_IS_THE_ID/view?usp=sharing)\n",
        "model_file_id = 'YOUR_GOOGLE_DRIVE_FILE_ID_HERE'\n",
        "\n",
        "# Local path where the model will be saved within the Colab environment\n",
        "model_local_path = './ozrock/model/best-model.pt'\n",
        "\n",
        "# Ensure the destination folder exists\n",
        "!mkdir -p ./ozrock/model\n",
        "\n",
        "# Download the model\n",
        "print(f\"Downloading model from Google Drive (ID: {model_file_id})... Make sure the file is shared with 'Anyone with the link'.\")\n",
        "!gdown --id {model_file_id} -O {model_local_path}\n",
        "print(\"Model downloaded successfully.\")\n",
        "\n",
        "# Load the model from the local path\n",
        "model = SequenceTagger.load(model_local_path)"
      ],
      "metadata": {
        "id": "n8twkGIPy0y4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. Get Sentences from Example PDF Files\n",
        "Specify the directory containing your example PDF files and extract sentences using the defined function."
      ],
      "metadata": {
        "id": "q-VxbhwhzjnE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PDF_DIR = \"./ozrock/IRpdfs\"\n",
        "sentences = pdf_to_sentences(PDF_DIR)\n",
        "print(f\"Extracted {len(sentences)} sentences from example PDFs.\")"
      ],
      "metadata": {
        "id": "ZuKS3pM6zp4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Load the Annotated Dataset\n",
        "Load your gold-standard annotated data from a CSV file. This data will be used as the true labels for evaluation."
      ],
      "metadata": {
        "id": "2pqxJVv_0Haz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "annotated_data = pd.read_csv(\"./ozrock/annotated-ozrock.csv\")\n",
        "labeled_data = []\n",
        "for index, row in annotated_data.iterrows():\n",
        "    text = row[\"Text\"]\n",
        "    labels = row[\"new_label\"].split(\",\") # Assuming labels are comma-separated\n",
        "    sentence = Sentence(text, use_tokenizer=True)\n",
        "    tokens = [token.text for token in sentence.tokens]\n",
        "    labeled_data.append((tokens, labels))\n",
        "print(f\"Loaded {len(labeled_data)} annotated instances.\")"
      ],
      "metadata": {
        "id": "NetHZ3G00I8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Predict Labels\n",
        "Use the loaded model to predict NER tags for the sentences from your annotated dataset."
      ],
      "metadata": {
        "id": "U8EfklPF0OLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predicted_sentences = []\n",
        "for tokens, _ in labeled_data: # We only need tokens for prediction\n",
        "    sentence = Sentence(\" \".join(tokens))\n",
        "    model.predict(sentence)\n",
        "    predicted_sentences.append(sentence)\n",
        "\n",
        "# Prepare true_tags by extracting only the labels from labeled_data\n",
        "true_tags = [labels for _, labels in labeled_data]\n",
        "print(f\"Generated predictions for {len(predicted_sentences)} sentences.\")"
      ],
      "metadata": {
        "id": "syqhXtG90YSD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "7. Evaluation Function\n",
        "This function calculates and visualizes the confusion matrix and prints the classification report for the NER model's performance."
      ],
      "metadata": {
        "id": "varqWHyL0vTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(predictions: List[Sentence], true_values: List[List[str]]) -> None:\n",
        "    y_pred = []\n",
        "    y_true = []\n",
        "    skipped_instances = 0\n",
        "\n",
        "    for i, (pred_sentence, true_label_list) in enumerate(zip(predictions, true_values)):\n",
        "        pred_tags = [span.tag for span in pred_sentence.get_spans(\"ner\")]\n",
        "\n",
        "        # Ensure lengths match for a valid comparison\n",
        "        if len(pred_tags) != len(true_label_list):\n",
        "            skipped_instances += 1\n",
        "            continue\n",
        "\n",
        "        y_pred.extend(pred_tags)\n",
        "        y_true.extend(true_label_list)\n",
        "\n",
        "    print(f\"Skipped {skipped_instances} instances due to mismatched lengths.\")\n",
        "\n",
        "    # Calculate the confusion matrix and classification report\n",
        "    labels = sorted(list(set(y_true) | set(y_pred)))\n",
        "\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels, zero_division=0)\n",
        "    report = classification_report(y_true, y_pred, labels=labels, zero_division=0)\n",
        "\n",
        "    # Print the classification report\n",
        "    print(\"\\nClassification Report:\")\n",
        "    print(report)\n",
        "\n",
        "    # Plot the confusion matrix using Seaborn\n",
        "    plt.figure(figsize=(12, 10))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=labels, yticklabels=labels)\n",
        "    plt.xlabel(\"Predicted Label\")\n",
        "    plt.ylabel(\"True Label\")\n",
        "    plt.title(\"Confusion Matrix for NER Model Evaluation\")\n",
        "    plt.tight_layout()\n",
        "\n",
        "    # Save the figure with high DPI\n",
        "    plt.savefig('cm_ozrock_7pdfs.png', dpi=600)\n",
        "    # plt.show() # Uncomment to display the plot inline if running locally"
      ],
      "metadata": {
        "id": "FqsQmLtH06oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "8. Run Evaluation\n",
        "Execute the evaluation function with the predicted and true labels."
      ],
      "metadata": {
        "id": "DL3GbkbszzIz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(predicted_sentences, true_tags)"
      ],
      "metadata": {
        "id": "hh80AxbO1TcM"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}